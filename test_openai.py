import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI  # For OpenAI chat models
from langchain.schema import HumanMessage

# âœ… Load OpenAI API Key from .env file
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# âœ… Ensure API key is loaded
if not openai_api_key:
    raise ValueError("âŒ OpenAI API key is missing! Please check your .env file.")

# âœ… Initialize OpenAI Model
llm = ChatOpenAI(api_key=openai_api_key, model="gpt-4o", temperature=0)

# âœ… Test prompt to check response format
test_prompt = "Summarize this: AI is transforming industries."
response = llm.invoke([HumanMessage(content=test_prompt)])

# âœ… Print response type and content
print("ğŸ”¹ Response Type:", type(response))
print("ğŸ”¹ Response Content:", response)

# âœ… Handle different response formats
if isinstance(response, str):
    extracted_text = response.strip()
elif hasattr(response, "content"):  # For object-based response
    extracted_text = response.content.strip()
elif isinstance(response, dict) and "content" in response:
    extracted_text = response["content"].strip()
else:
    extracted_text = "âš ï¸ Error: Unexpected response format."

print("\nâœ… Extracted Text:", extracted_text)
